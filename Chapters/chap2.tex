%!TEX root = /Users/admin/Desktop/Documents/Academic/MA 470 -THESIS/THESIS/thesis.tex

\chapter{The \Picalc}\label{the picalc}	
	In this chapter, we will give the syntax of the \emph{asynchronous} \picalc\ and a discussion of its features.  
We will loosely follow the style of a recent presentation given in \cite{henn07}.  
Following this, we will introduce a notion of equivalence of terms in the language.  
There are two viewpoints from which the computation behavior of a process can be characterized.  
The first is a set of semantic reduction rules, given in \refsec{secreducationsemantics}, that focus on the way a process behaves in and of itself through internal evolution.
The second viewpoint is more general and addresses how a process evolves in the context of a larger system.
We give this important system in \refsec{secactionsemantics}.
Finally, we conclude the chapter with an extended example that provides an interesting \picalc\ implementation while demonstrating many of its systems and rules.
	\section{Syntax}\label{spisyntax}
	The terms of the \picalc\ operate on a space of \defmargin{identifiers} which consists of names $a,b,c,...,n,m,o$ for communication channels, and variables $v,w,x$ which can refer to channels, and recursive variables $p,q,r$, explained in more detail below.  
In general, we will use capital letter to denote a process.
	
		\begin{insettable}
		\begin{center}
		\begin{tabular}{r l l}
		\multicolumn{3}{c}{\emph{Process terms}}\\
		$R :=$  &$R_1 \comp R_2$ & Composition\\
		&\send{n}{\tuple{V}} & Send\\
		&$\receive{n}{\tuple{X}} R$ & Receive\\
		&$\new{n}R$ & Restriction\\
		&$\pif{v_1 = v_2}\pthen R_1 \pelse R_2$ & Matching\\
		&$\rec{p} R$ & Recursion\\
		&\pstop & Termination\\
		&\\
		
		\multicolumn{3}{c}{\emph{System}} \\
		& $\new{c_1,...,c_n} R_1 \comp...\comp R_m$ & $n, m >= 0$\\
		\end{tabular}
		\caption{\emph{Terms in the asynchronous \picalc}}\label{apicalcterms}
		\end{center}
		\end{insettable}
		\todo{Get index up to snuff by making sure more terms are margin defined.}
	Given two or more processes, we can compose them using the $\comp$ operator, which means that the composed processes will be executed concurrently.\index{parallel}
		
	\index{message passing}We denote the sending of a message $\tuple{V}$\index{tuple} over a channel $n$ by \send{n}{\tuple{V}}.  
Here $\tuple{V}$ is a tuple of identifiers in the form $\tuple{V}=(v_1,...,v_k):k\geq 0$.  
We say that $\tuple{V}$ has \defmargin{arity} $k$.  
In the case $k=0$ nothing is being transmitted; the communication acts as a \defmargin{handshake} or signal.  
We will denote this case by \send{n}{}.  
When $k=1$, only a single value $v_1$ is being transmitted, in which case we write $\send{n}{v_1}$.  
Because our calculus is \inidx{asynchronous}, sending is not a \defmargin{guarded} operation -- that is, a send operation does not continue to execute any process after sending its value, but simply terminates after sending the value.  
We will show in \refex{exsynchronous} that synchronous behavior can still be modeled in our language.
	
	The term \receive{n}{\tuple{X}}$R$ describes a process waiting to receive a tuple along $n$ before continuing with $R$.  
Here $\tuple{X}$ is a \defmargin[pattern]{patterns} -- a tuple of variables of arity $k$ -- which can be used anywhere in $R$.  
Patterns allow us to decompose the transmitted tuple into its component values by naming them with $x_1,...,x_k$, which can be referred to in $R$.  
Thus, in the term
	\begin{align}
		\send{c}{n_1,n_2,n_3} \comp \receive{c}{x_1,x_2,x_3} R,
	\end{align}
the names $n_1,n_2,n_3$ are received via $c$ and correspond to the variables $x_1,x_2,x_3$ in the pattern.  
 Hence, the variables $x_1,x_2,x_3$ can be used anywhere within the process $R$ to mean $n_1,n_2,n_3$.  


Similarly to sending, the case of arity 0 is denoted \receive{n}{}$R$ -- here $R$ will not happen until a handshake is received on $n$.  
Notice that in contrast to the case of sending, receiving is a \inidx{guarded} operation -- that is, the process $R$ will execute after $\tuple{X}$ has been received via $n$.  
For example, the term
\begin{align}
	\receive{c}{}\pstop
\end{align}
represents a `listener'	process that simply consumes the value waiting on input channel $c$.  
The term \pstop\ describes a terminating process: one that simply halts.

	\index{scope restriction}The term $\new{n} R$ describes a process in which a new channel name $n$ is created and limited to being expressed in the process $R$ (we say the \defmargin{scope} of $n$ is \emph{restricted} to $R$).  
We shall see that scope plays a very big role in the way processes can establish new connections.  
Essentially, for a process $P$ to have a connection to another process $R$ really means that they both `know' about a common channel $c$.  
In that case, $c$ is scoped $P$ and $R$.  
Hence, $\new{n} R$ really means that we have created a channel $n$ that -- for the time being -- only process $R$ knows about.  
It is important to note that $n$ \emph{can} be used outside of $R$ if it is sent and then received by some outside process.  
This feature is known as \defmargin{scope extrusion}, and is the underpinning for the dynamic communication topologies introduced in the \picalc.  
For example, in the term
\begin{align}
	\new{n} (\send{c}{n}) \comp \receive{c}{x} \send{x}{},
\end{align}
	we have a channel $n$ scoped to the left hand process which is sending $n$ over $c$. 
	The right hand process then receives $n$ over $c$ (referred to by $x$) and then sends an empty signal over $n$.  
At the time of its creation, $n$'s scope is just the left half of the term.  
However, after $n$ is received in the right hand process it will be able to be referred to outside of its initial scope.  
We will give a precise account of how this happens in our reduction rules and \refex{exscopeextr} below.
	
	We will sometimes abbreviate terms that use multiple channel restrictions by writing $\new{n,m}R$ to denote the term $\new{n}(\new{m}R)$. 
	
	Simple conditional execution based on value equality comparison is available through the use of $\pif{v_1 = v_2}\pthen R_1 \pelse R_2$.  
For example, in the following term, the value received on $c$ is checked; if it matches $a$ then a handshake is sent along $a$ (which is referred to by $x$), otherwise the process terminates.
	\begin{align}
		\receive{c}{x}(\pif{x=a} \pthen \send{x}{} \pelse \pstop)
	\end{align}
	
	Recursion is built into the language using the syntax $\rec{p}R$.  
The process $\rec{p}R$ itself is referred to by to the variable $p$, which is used somewhere in $R$ to express a recursive call.  
For example, consider the recursive responder term below, which receives a channel $x_1$ via $c$.  
It then sends a handshake response on $x_1$, while another responder process is run in parallel.
	\begin{align}
		\rec{p}\receive{c}{x_1}(\send{x_1}{} \comp p)
		\label{reclistenerterm}
	\end{align}
The variable $p$'s scope is restricted $R$, just as $\tuple{X}$ is restricted to $R$ in $\receive{c}{\tuple{X}}R$ and $n$ is restricted to $R$ in $\new{n}R$.
	
	The composition operator$\comp$should be seen as having higher ordering priority than the other operators.  Thus, for example, $\new{n}R \comp Q$ should be read as $(\new{n}R) \comp Q$.  Operators that join using the dot (.) notation should always be taken as being grouped together.  Thus, $\new{c}\receive{c}{x}\send{a}{b}$ should be read as $\new{c}(\receive{x}{x}\send{a}{b})$ and not $(\new{c}\receive{x}{x})(\send{a}{b})$.
	
	We call a collection of parallel processes communicating over shared channels a\emph{\inidx{system}}.  
Note that a system is itself a process.  
Though not strictly a primitive of the \picalc, it is nonetheless a helpful construct for understanding the way that behavior can be modeled using processes as atoms.
\begin{example}{exsummation}
	 Many presentations (including our own in the next chapter) of the \picalc\ involve a \inidx{choice} or \inidx{summation} operator as in $P+Q$ for two processes terms $P$ and $Q$.  
The meaning is essentially that either $P$ or $Q$ can be non-deterministically executed, and the other process will not be.  
However, we can model the same behavior without defining a choice operator:
	\begin{align}
		\send{c}{} \comp \receive{c}{}P \comp \receive{c}{}Q
	\end{align}
	In the above process, either $Q$ or $P$ (but not both) could be executed.  
This is due to the asynchronous behavior of our language -- sending an empty signal along $c$, we cannot control which process consumes the signal (or even if it will be consumed at all). 
Thus, even without the choice operator our calculus is non-deterministic\index{non-determinism}.
\end{example}

\begin{example}{exsynchronous}
	 Perhaps we are not happy with this asynchronous transmission behavior.  
Surely we'd like to have blocking sends sometimes, or be able to guarantee that a value is received.  
Our asynchronous calculus can model \inidx{synchronous} sending by using a private channel that acknowledges when a value is received.  
To see how, consider the following system:
	\begin{align}
		F_1(c) & \pdef \rec{z} (\new{ack}(\send{c}{ack} \comp \receive{ack}{}(R \comp z)))\\
		F_2(c) & \pdef \rec{q} (\receive{c}{ack}(\send{ack}{} \comp q)) \\
		Sys_1 & \pdef \new{d}(F_1\langle d \rangle \comp F_2\langle d\rangle)
	\end{align}
	Above, both $F_1$ and $F_2$ have (infinite) recursive behavior, and we can think of $Sys_1$ as a term that `kicks off' both of them after creating a shared channel for them to communicate on.  

	
	In an iteration of $F_1$, a new channel $ack$ is created for acknowledgement.  
This channel is sent along $c$ and then $F_1$ waits for input on $ack$ before executing some term $R$ and calling another iteration.  
$F_2$ receives $ack$ along $c$ and then uses $ack$ to send an empty signal to $F_1$ that it has received input on $c$.  

	
	This is just a toy example: the only thing being communicated is the acknowledgement channel itself.  
We might imagine a more complex system where $F_1$ sends more input along $c$ and waits to make sure $F_2$ receives it.  
Note that the channel $ack$ is only used \emph{once} -- we want to ensure that the acknowledgement that $F_1$ receives is definitely for \emph{that} instance of communication that it just initiated.  
This allows us to guarantee that $F_2$ has executed before $F_1$ continues with R.  
\end{example}

\section{Structural Equivalence}
	A natural question at this point is, given two \picalc\ terms, how can we determine if they are equivalent?  Intuitively, we want them to be equivalent if they \emph{act} the same, but actually defining this equivalence relation can be a bit subtle.  
In exploring this issue, we will first look at identifier substitution, giving rules for when we can safely interchange identifiers without creating a different term. 
Following this, we will develop the notion of \emph{contexts} and then use it to build an equivalence relation among processes.\index{equivalence}
\subsection{Identifier Substitution and $\alpha$-equivalence}\label{secSubst}
	As a first step in our notion of equivalence, we might assert that the way identifiers are named shouldn't change how they act.  
However, this doesn't mean we can start interchanging symbols with carefree abandon.  
In a component process, some terms might be important for how the process acts in a larger system.  
For example, if we changed the channel that a mobile phone uses to communicate with a tower, that phone certainly wouldn't act the same -- the tower would no longer know how to talk to it.  
On the other hand, we should be able to change any of the channels that the phone uses to communicate internally with itself without much issue.
	
	The only identifiers we can safely change in a process without potentially affecting the way it behaves in a larger system are \defmargin[bound identifiers]{bound}.\refmargin{identifiers}\!\!\!\!
Intuitively, bound identifiers are those which are introduced by some name-binding operator within the process term.
There are three \picalc\ operators that bind identifiers.
First, a name $n$ is bound in the process term $R$ to a new channel by the restriction operator as in \new{n}$R$.  
Second, each channel variable $x_i$ in the pattern $X$ is bound in $R$ to some channel $v_i$ from the sending process when matched in a receive expression \receive{c}{X}$R$.  
Finally, the recursive variable $x$ is bound within $R$ in the recursive expression $\rec{x}R$, bound particularly to the whole process itself.
	We denote the set of bound identifiers in a term $R$ by $bi(R)$; all those which are not bound we call \defmargin[free]{free identifiers}, denoting them $fi(R)$.  
Similarly, we denote the set of bound and free channel names in a term $R$ by $bn(R)$ and $fn(R)$, respectively.  
We call a term with no free identifiers \defmargin[closed]{closed terms}.
	
	For example, in the term:
	\begin{align}
		\rec{p}\receive{c}{x_1}(\send{x_1}{} \comp p),
	\end{align}
	$p$ is a bound recursive variable, while $x_1$ is bound by the receive operator. 
	The channel $c$ is free.  
Now consider the term
	\begin{align}
		\send{c}{n} \comp \new{n}(\rec{p}\receive{c}{x_1}(\send{x_1}{} \comp p))
	\end{align}
	Here $x_1, p$ are bound as before.  
However, the use of $n$ being sent on $c$ is \emph{not} bound, since it occurs outside the scope of the restriction operator.  
In fact, the following term (with the restriction operator removed) is equivalent (see \refex{exelimscoperest} for justification).
	\begin{align}
		\send{c}{n} \comp \rec{p}\receive{c}{x_1}(\send{x_1}{} \comp p)
	\end{align}
	When a receive term like $\receive{c}{X}R$ is executed, we substitute the free variables $\tuple{X}$ occurring in $R$ with the values $\tuple{V}$ that were received.  
We denote the term that results from such substitutions by $R$\subst{\tuple{V}}{\tuple{X}}.  
During the course of a substitution, we might inadvertently `capture' a bound term.  
For example, suppose the system
\[
	P\langle a\rangle \comp \send{a}{n}\\
\]
where $P(a)$ is given by
\begin{align}\label{subs_processpa}
	P(a) \pdef \receive{a}{x}(\new{n}(\send{n}{} \comp \send{x}{}))
\end{align}
In running $\receivenodot{a}{x}$ we would perform the substitution \subst{n}{x}.\index{substitution}
But the received term $n$ is not the same as the $n$ occurring in $P(a)$ -- it was a free channel sent by a the process $\send{a}{n}$ outside the scope restriction $\new{n}$  Thus, the problem in performing $\subst{n}{x}$ is that it would have the free name $n$ from the outside process bound as if it where the same $n$ bound by $P(a)$.  
We say that performing this substitution would \defmargin{capture} the bound name $n$.  
We can avoid this by first replacing the bound $n$ with a new name that is `fresh' -- that is it does not occur elsewhere in the term.  
For example:
\begin{align}
	P{'}(a) \pdef \receive{a}{x}(\new{n'}(\send{n'}{} \comp \send{c}{}))
\end{align}
We can now safely perform the receive and the corresponding substitution, yielding
\begin{align}
	\new{n'}(\send{n'}{} \comp \send{n}{})
\end{align}
Obviously we want to say $P(a)$ and $P^{'}(a)$ are equivalent.  
In general when two terms are the same up to their choice of bound identifiers, we say they are \defmargin[$\alpha$-equivalent]{$\alpha$-equivalency}, and write $P(a) \equiv_\alpha P^{'}(a)$.  
Though this can be treated more explicitly, from now on when we perform a substitution $R\subst{\tuple{V}}{\tuple{X}}$, we will implicitly pick a term $\alpha$-equivalent to $R$ where the substitution will not capture terms bound in $R$.  
From now on we will intend that a term represents its entire $\alpha$-equivalency class, and thus will not explicitly specify $\alpha$-equivalency in the equivalence relation introduced below.

Notice the use of interfaces\refmargin{interface} to define the process $P(a)$ in (\ref{subs_processpa}).
When a process has free channel names occurring in its body, as is the case with $a$, we will sometimes place those names inside parentheses after the the process to suggest a process' interface.  
We say that a process $Q$ with interface $Q(\tuple{V})$ \defmargin{exposes} the names $\tuple{V}$.  
The idea is that since these terms are free, when the interface is used as a component in a larger system, we can have other components that expose the same channels.  
That way, our system can bind those channels at the top level and its components can communicate on them.  
For example, consider the following system:
\[
	\new{b,c}Q_1\langle b\rangle \comp Q_2\langle b,c\rangle
\]
Here we are assuming the existence of some process $Q_1$ exposing $b$ and some process $Q_2$ exposing $b$ and $c$.  Both process components $Q_1$, $Q_2$ both expose a common name $b$, which the system has bound.  
When some larger system uses $new$ to bind channels that are exposed by a component interface we say that system \defmargin[instantiates]{instantiate} the interface.
Since usage of $b$ in the processes is free, $b$ is not captured when it is bound by the system.  
Instead, both processes have the bound term in common, and can use it to interact.
\subsection{Contexts and Equivalence}
Perhaps the next idea we might have for building our equivalence relation is that equivalent processes should act the same when dropped into any larger system.  
Let us define more precisely what we mean by `dropping in' a process.
\begin{definition}{Context}
	A context $\mathbb{C}$ is given by:
	\[
		\mathbb{C} := \begin{cases}
		[\ ]\\
		\mathcal{C} \comp Q \text{ or } Q \comp \mathcal{C} & \text{for any process $Q$, context $\mathcal{C}$}\\
		\new{n}\mathcal{C} & \text{for any name $n$, context $\mathcal{C}$}.
		\end{cases}
	\]
	$\mathbb{C}[Q]$ denotes the result of replacing the placeholder $[\ ]$ in the context $\mathbb{C}$ with the process term $Q$.
	\end{definition}
	Notice that with contexts, we do not pay any attention to whether a name in $Q$ is bound in $\mathbb{C}$.  
Hence, unlike with substitution, free variables in $Q$ can become bound in $\mathbb{C}[Q]$.  
So, for example, channel $c$ in the process $P(c) \pdef \receive{c}{}R$ can become bound in $\mathbb{C}[P(c)]$ where $\mathbb{C}[\ ]$ is the context
\[
	\new{c}\send{c}{} \comp [\ ]
\]
We say that a relation $\sim$ between processes is \defmargin{contextual} if $P\sim Q$ implies $\mathbb{C}[P]\sim \mathbb{C}[Q]$ for any context $\mathbb{C}$.  
We are now ready to define our notion of equivalency using contexts.
	\begin{definition}{Structural Equivalence}
		Structural Equivalence, denoted $\sequiv$ is the smallest contextual equivalence relation that satisfies the following axioms:
		\begin{align*}
			P \comp Q\ &\  \sequiv\  Q \comp P && \text{\tiny{(S-COMP-COMM)}}\\
		 	(P \comp Q) \comp R\ &\ \sequiv\ P \comp (Q \comp R) && \text{\tiny{(S-COMP-ASSOC)}}\\
			P \comp \pstop\ &\ \sequiv\ P && \text{\tiny{(S-COMP-ID)}}\\
			\new{c} \pstop\ &\ \sequiv\ \pstop && \text{\tiny{(S-REST-ID)}}\\
			\new{c}\new{d} P \ &\ \sequiv\ \new{d}\new{c} P && \text{\tiny{(S-REST-COMM)}}\\
			\new{c}(P \comp Q)\ &\ \sequiv\  P \comp \new{c}Q\text{, if } c\not\in \mbox{fi}(P) && \text{\tiny{(S-REST-COMP)}}
		\end{align*}
	\end{definition}
	These axioms are simply a set of syntactic rules we use to identify as the same processes that are syntactically different.  
The first and second state that composition is commutative and associate.  
Thus, we will omit parentheses around compositions when our meaning is clear.  
(S-COMP-ID) states that a terminated process can be eliminated from a composition.  
(S-REST-ID) states that a channel scope restriction operator can be eliminated when its scope is only over a terminated process. (S-REST-COMP) states that scope ordering does not matter, justifying our shorthand $\new{c,d} P$.  
The last of these axioms is most important -- it is the basis for\refmargin{scope extrusion}\emph{scope extrusion}, upon which process\refmargin{mobility} mobility is based (as we shall demonstrate in \refex{exscopeextr} below).
	
	\begin{example}{exelimscoperest}
		In our discussion of bound identifiers above, we asserted that we can eliminate a scope restriction operation when none of the scoped identifiers occur in its scope. 
		We can now show why this is permissible:
		\begin{align*}
			&\ \new{n,m}\receive{a}{x_1,x_2}\send{x_1}{}\comp \rec{x}(\send{a}{n,m} \comp x) &&\\
			\sequiv\ &\ \new{n,m}(\receive{a}{x_1,x_2}\send{x_1}{} \comp \pstop)\comp \rec{x}(\send{a}{n,m} \comp x) && \text{\tiny{(S-COMP-ID)}}\\
			\sequiv\ &\ \receive{a}{x_1,x_2}\send{x_1}{} \comp \new{n,m}\pstop\comp \rec{x}(\send{a}{n,m} \comp x) && \text{\tiny{(S-REST-COMP)}}\\
			\sequiv\ &\ \receive{a}{x_1,x_2}\send{x_1}{} \comp \pstop \comp \rec{x}(\send{a}{n,m} \comp x) && \text{\tiny{(S-REST-ID)}}\\
			\sequiv\ &\ \receive{a}{x_1,x_2}\send{x_1}{} \comp \rec{x}(\send{a}{n,m} \comp x) && \text{\tiny{(S-COMP-ID)}}
		\end{align*}
	\end{example}
\section{Reduction Semantics}\label{secreducationsemantics}
We are now ready to give the \emph{semantic} properties that a process in our language should possess.  
By specifying the behavior of processes, we define how computation proceeds in the \picalc.  
The set of rules given below show how a process can internally evolve through a number of computation steps.\index{internal evolution}\todo{make all index terms lowercase}
\begin{definition}{Reduction}
	The \emph{reduction relation} \pred\ is the smallest contextual relation that satisfies the following rules:
	\begin{center}\begin{tabular}{rll}
		$\send{c}{\tuple{V}} \comp \receive{c}{\tuple{X}}R$\ &\  $\pred\  R\subst{\tuple{V}}{\tuple{X}}$ & \tiny{(R-COMM)}\\
		$\rec{p}R$\ &\  $\pred\  R\subst{\rec{p}R}{p}$ & \tiny{(R-REP)}\\
		$\pif{v = v}\pthen P \pelse Q$\ &\ $\pred\ P$ & \tiny{(R-EQ)}\\
		$\pif{v_1 = v_2}\pthen P \pelse Q$\ &\ $\pred\ Q$ \ \ (where $v_1\neq v_2$)& \tiny{(R-NEQ)}\\
		\multicolumn{2}{c}{\hspace{4.5em}$\underline{P\sequiv P', P \pred Q, Q\sequiv Q'}$} & \multirow{2}{*}{\tiny{(R-STRUC)}}\\
		\multicolumn{2}{c}{\hspace{4.5em}$P'\pred Q'$}
	\end{tabular}\end{center}
	We use the notation $P\preds Q$ when an arbitrary number of these rules have been applied in reducing $P$ to $Q$.
\end{definition}
The first of these allows a computation step for the transmission of values over a channel.  Note that we only allow the application of (R-COMM) when the substitution $\subst{\tuple{V}}{\tuple{X}}$ makes sense.  
That is, $\tuple{V}$ and $\tuple{X}$ must have the same arity\refmargin{arity} and in a typed system we'd want to ensure that their types were compatible\footnote{See \cite{henn07} for a discussion of type systems for the \picalc.}.
(R-EQ) enables a computational step for value-matching.  
For example, in
\[
	\send{c}{a} \comp \receive{c}{x} \pif{x=a} \pthen P \pelse \pstop  
\]
we apply (R-COMM) to obtain
\[
	\pif{a=a} \pthen P \pelse \pstop  
\]
from which we can apply (R-EQ) to obtain $P$.
(R-REP) allows us to unravel a recursive expression so that it contains replicas of itself.  
For example,
\[
	\rec{p} \send{c}{} \comp p
\]
expands to
\[
	\send{c}{} \comp (\rec{p} \send{c}{} \comp p)
\]
Finally, (R-STRUCT) says that a reduction is defined up to structural equivalence.  
We give an example of its use below.
\begin{example}{exscopeextr}
	We will give a demonstration of how scope extrusion\refmargin{scope extrusion} is obtained using the rules and axioms of reduction and structural equivalence.  
Consider the expression 
\begin{align}\label{exscopeextr_eqn1}
	\receive{d}{x}\send{x}{}\comp \new{c}(\send{d}{c} \comp \receive{c}{}\pstop)	
\end{align}
You can see above that $c$'s scope can be extruded by sending over $d$ and that the left side of the term will then use $c$ to communicate with the right side.  
Now we will show that this is enabled by the reduction rules.  
First, we can use (S-REST-COMP) to bring the restriction to the outside, giving:
\begin{align}\label{exscopeextr_eqn2}
	\new{c}(\receive{d}{x}\send{x}{}\comp \send{d}{c} \comp \receive{c}{}\pstop)		
\end{align}
	Since (\ref{exscopeextr_eqn1}) is equivalent to (\ref{exscopeextr_eqn2}), we can apply (R-STRUCT) to deduce that if \label{exscopeextr_eqn2} reduces to some $Q$, then (\ref{exscopeextr_eqn1}) will.
	To find this $Q$, we can apply (R-COMM), which we can do inside of the restriction operator thanks to the reduction relation's contextuality, and apply a substitution to (\ref{exscopeextr_eqn2}), resulting in:
\begin{align}
	\new{c}(\send{c}{} \comp \receive{c}{}\pstop)
\end{align}
	Finally, we can apply (R-COMM) again, so the process simply reduces to \pstop.  


	Now let $P(d)$ be the right half of our original process, and $\mathbb{C}$ be the remaining context:
	\begin{align}
		P(d) \pdef \new{c}(\send{d}{c} \comp \receive{c}{}\pstop)
	\end{align}
	\begin{align}
		\mathbb{C} = \receive{d}{x}\send{x}{} \comp [\ ]
	\end{align}
Then we have shown that if we drop the component $P(d)$ into the context $\mathbb{C}$ (forming $\mathbb{C}[P\langle d \rangle]$), it will establish a new channel $c$ and extend its scope, using $d$.
This means that components that are `dropped in' to a larger system can create new channels on the fly and then extrude them to communicate with the rest of the system (provided they share at least one channel to begin with).  
In fact, this is the very procedure that allows a system to change its communication topology dynamically via scope extrusion.
\end{example}

\section{Action Semantics}\label{secactionsemantics}
Our description of process behaviors so far has been limited to talking about the internal computational steps through which it might evolve.  
Now, we want to give a more general description of how a process might evolve when placed within the context of a larger system.  
A process can interact with other processes within such a system by sending or receiving values along channels they share.  
To describe these abilities, we will use the notion of a \emph{labelled transition system}, or \emph{lts}.

\begin{definition}{Labelled Transition System}
	A \emph{labelled transition sytem} $\mathcal{L}$ is a tuple $(\mathcal{S}, \mathcal{A})$ 
where $\mathcal{S}$ is a set of processes and $\mathcal{A}$ is a set of labels called \emph{actions}.  
Furthermore, for each action $\alpha$, there is a binary relation:
	\[
		R_{\alpha} \subseteq \mathcal{S} \times \mathcal{S}
	\]
	To denote that $\langle P,Q\rangle \in R_{\alpha}$, we will use the notation $P \evolves{\alpha} Q$.
\end{definition}
Hence, the transition $P \evolves{\alpha} Q$ indicates that there is an action under which the process P becomes Q.  
We will refer to $Q$ is the \defmargin{residual} of $P$ after $\alpha$.

There are three types of actions that may cause a process to evolve.  
First, the process might receive a value.  
That is, a process $P$ is said to be capable of making the transition $P \evolves{\receives{c}{\tuple{X}}} Q$, which is to say that $P$ can receive $\tuple{X}$ along $c$ to become the residual process $Q$.  
The capability of a process to evolve in this way is given by the rule (A-IN) in \reffig{apiactionrules}, which says that for a general process $c$ and input $\tuple{V}$
\[
	\receive{c}{\tuple{X}}R \evolves{\receives{c}{\tuple{V}}} R\subst{\tuple{V}}{\tuple{X}}
\]
As with (R-COMM), evolution under (A-IN) is only possible when the substitution $\subst{\tuple{V}}{\tuple{X}}$ makes sense.
For example, a process $\send{c}{\tuple{V}} \comp P$ will evolve to $\pstop \comp P \sequiv P$ when it exercises its capability for output on $c$.  

The second type of action available is sending.  
Here we need to be a bit more careful.  
In the case of receiving, the received names are always bound to new names in $\tuple{X}$, so we needn't worry about issues of scope.  
In sending, however, we might be transmitting either free or bound names, or a mix of them.  
In the latter case, we need to take account of the fact that the\refmargin{scope extrusion}scope of the bound name is being extruded to whatever process receives the name.  
We denote the set of names that are bound\refmargin{bound} in the send action by $\exports{\tuple{B}}$, and we say that this set of names is \defmargin{exported} by the process.  
Hence, the transition $\send{c}{\tuple{V}} \evolves{\exports{\tuple{B}}\sends{c}{\tuple{V}}} \pstop$ expresses the capability to send the values $\tuple{V}$ over $c$, exporting $\exports{\tuple{B}}$ and resulting in $\pstop$.  
For example,
\[
	\new{d}(\send{c}{d} \comp Q) \evolves{\exports{d}\sends{c}{d}} Q
\]
The capability of a process to evolve by sending a value is described by (A-OUT) for a general channel $c$ and output values $\tuple{V}$:
\[
	\send{c}{\tuple{V}} \evolves{\sends{c}{\tuple{V}}} \pstop 
\]
We will refer to sending and receiving as \defmargin[external actions]{external action}.

Our third action we call \defmargin{internal action}. 
This is caused by some internal evolution in $P$ like those described by (R-COMM) in our \refsec{secreducationsemantics}.  
We call actions like sending and receiving external since in order to occur, they need some external process (given in some system of which the process in question is a part) to do the corresponding receiving or sending.  
However, with internal action there is no external process needed to proceed.  
We use $\tau$ to denote such an internal evolution step.  
Thus, we say $P \evolves{\tau} Q$ if $P$ is able evolve into $Q$ by performing a reduction step without any external contributions.  
For example (thanks to (R-COMM)),
\[
	\send{c}{a} \comp \receive{c}{x}\send{x}{} \evolves{\tau} \send{a}{} 
\]
The capability for $\tau$ is defined through the rules (A-COMM), (A-REP), (A-EQ) and (A-NEQ).  (A-REP), (A-EQ) and (A-NEQ) simply provide the same internal evolution capabilities as (R-REP), (R-EQ) and (R-NEQ) do in the \hyperref[secreducationsemantics]{reduction semantics}. (A-COMM), however, is more subtle then (R-COMM).  We describe it below, after a discussion of some of the other rules in action semantics.

We define the action relation under the following rules (with their preconditions listed alongside them):
\todo{make the arrow for evolution size according to the text above it}
\begin{definition}{Action}\label{apiactionrules}
	The \emph{action relation} \evolves{} is the smallest relation between processes that satisfy the following rules:
	\begin{center}\begin{tabular}{rllll}
 		$\receive{c}{\tuple{X}}R$ & \evolves{\receives{c}{\tuple{V}}} & R\subst{\tuple{V}}{\tuple{X}} & & \tiny{(A-IN)}\\
		$\send{c}{\tuple{V}}$ & \evolves{\sends{c}{\tuple{V}}} & $\pstop$ & & \tiny{(A-OUT)}\\
		$\rec{x}R$ & \evolves{\tau} & $R\subst{\rec{x}R}{x}$ & & \tiny{(A-REP)}\\
		$\pif{v=v} \pthen P \pelse Q$ & \evolves{\tau} & $P$ & & \tiny{(A-EQ)}\\[10pt]
		$\pif{v_1=v_2} \pthen P \pelse Q$ & \evolves{\tau} & $Q$ & $v_1 \neq v_2$ & \tiny{(A-NEQ)}\\[10pt]

		\multicolumn{3}{c}{$\underline{P \evolves{\alpha} P'}$} & \multirow{2}{*}{\footnotesize{$\textstyle bn(\alpha) \cap fn(Q) = \emptyset$ }} & \multirow{2}{*}{\tiny{(A-COMP)}}\\
		\multicolumn{3}{c}{$P\comp Q \evolves{\alpha} P'\comp Q$}\\[10pt]
		
		\multicolumn{3}{c}{$\underline{P \evolves{\alpha} P'}$} & \multirow{2}{*}{\footnotesize{$\textstyle b \not \in n(\alpha)$ }} & \multirow{2}{*}{\tiny{(A-REST)}}\\
		\multicolumn{3}{c}{$\new{b} P \evolves{\alpha} \new{b} P'$}\\[10pt]

		\multicolumn{3}{c}{$\underline{P\evolves{\exports{\tuple{B}}\sends{c}{\tuple{V}}} P'}$} & \multirow{2}{*}{\footnotesize{$n \neq c, n\in \tuple{V}$ }}& \multirow{2}{*}{\tiny{(A-OPEN)}}\\
		\multicolumn{3}{c}{$\new{n}P \evolves{\exports{n,\tuple{B}}\sends{c}{\tuple{V}}} P'$}\\[10pt]
		
		\multicolumn{3}{c}{$\underline{P\evolves{\receives{c}{\tuple{X}}} P',\ Q \evolves{\exports{\tuple{B}}\sends{c}{\tuple{V}}} Q'}$} & \multirow{2}{*}{\footnotesize{$\textstyle \exports{\tuple{B}}\cap fn(P) = \emptyset$ }} & \multirow{2}{*}{\tiny{(A-COMM)}}\\
		\multicolumn{3}{c}{$P\comp Q \evolves{\tau} \new{\tuple{B}}(P'\comp Q')$}\\[10pt]
	\end{tabular}\end{center}
\end{definition}\note{I wonder if these couldn't be simplified (ie removing A-EQ, A-REP, etc.) by allowing a transition that happens over the reduction semantics?  my sense is this approach is avoided because the action relation isn't actually contextual in our above definition (since we need to be more careful about bound variable captures).  i wonder if there is a way to gracefully sidestep the issue and avoid all the redundancy...}

Together, (A-COMP) and (A-REST) provide a capability similar to \refmargin{contextual}contextually.  
That is, given that $P \evolves{\alpha} P'$, (A-COMP) allows us to `drop in' P alongside a progress $Q$ running in parallel, forming $P\comp Q \evolves{\alpha} P' \comp Q$.
Similarly, (A-REST) allows us to drop $P$ into a new scope restriction operator, forming $\new{b}P \evolves{\alpha} \new{b}P'$.
The key difference between these rules and contextually is that here we need to be careful about inadvertently capturing bound variables.
The action $\alpha$ could export names, so we need to make sure those names don't conflict with names in the process we are trying to infer.

Thus, in (A-REST) we require that the newly bound variable $b$ does not occur in the names $n(\alpha)$ of the action $\alpha$.  
By $n(\alpha)$, we mean the channel name itself, along with all the names $\tuple{V}$ in the case of a send action.
Suppose we ignored this precondition and tried the following:
\begin{center}\begin{tabular}{rllll}
	\multicolumn{3}{c}{$\underline{\receive{c}{}\pstop \evolves{\receives{c}{}} \pstop}$} & & \multirow{2}{*}{\tiny{(A-REST)}}\\
	\multicolumn{3}{c}{$\new{c} \receive{c}{}\pstop \evolves{\receives{c}{}} \new{c} \pstop$}\\[10pt]
\end{tabular}\end{center}
This is not what we want.  
We should not allow $\new{c} \receive{c}{}\pstop$ to evolve since the scope of $c$ cannot be extruded and thus no other process could ever send along $c$!  
Similarly, we should not allow the the introduced restriction to have the same channel name as any of the values transmitted in $\alpha$.  
We wouldn't want to end up, for example, with an action relation like 
\[
	\new{b} \send{c}{b} \evolves{\sends{c}{b}} \new{b} stop
\]
since this would imply that $b$'s scope hasn't been extruded when it fact it has.


In (A-COMP), we need to ensure that none of the bound names of $\alpha$ conflict with the free variables in $Q$.  
There are no names (only variables) in a receive expression.  
The only names that are bound in an action are those of the set $\exports{\tuple{B}}$ exported by a send action.  
Thus, the precondition on (A-COMP) simply requires that bound names that are transmitted will be `fresh' in the composed process $Q$.  
For example, consider the following:
\begin{center}\begin{tabular}{rllll}
	\multicolumn{3}{c}{$\underline{\new{b}\send{c}{b}\evolves{\exports{b}\sends{c}{x}} \pstop}$} & & \multirow{2}{*}{\tiny{(A-COMP)}}\\
	\multicolumn{3}{c}{$\new{b}\send{c}{b} \comp \send{b}{a}\evolves{\exports{b}\sends{c}{x}} \pstop\comp \send{b}{a}$}\\[10pt]
\end{tabular}\end{center}
Above, we have a process sending on $b$ but the scope of $b$ has \emph{not} been extruded (it hasn't been received on $c$).
We don't want to allow $b$'s scope to be `accidentally' extruded simply by capturing a free $b$ somewhere in $Q$.
Hence, we need to be careful not to `capture' a channel like $b$ by allowing exported channels to have the same name as free variables outside the original scope of the process.

(A-OPEN) expresses scope extrusion of a name $n$.  
Essentially, if we already know that 
\[
	P\evolves{\exports{\tuple{B}}\sends{c}{\tuple{V}}} P'
\]
then we can take a name $n\in n(\tuple{V})$ and bind it, inferring
\[
	\new{n} P\evolves{\exports{n,\tuple{B}}\sends{c}{\tuple{V}}} P'
\]
The name $n$ is then exported as well.
Note that $n$ cannot be $c$ since restricting $n$ (i.e. $c$) to $P$ would cause a scoping issue that interfered with an outside process' ability to receive on $c$.

Finally we have (A-COMM), which expresses scope extrusion as well but this time in the context of the internal action that we described with (R-COMM) in the reduction semantics.  
Suppose we have that $P \evolves{\receives{c}{\tuple{X}}} P'$ and $Q \evolves{\exports{\tuple{B}}\sends{c}{\tuple{V}}} Q'$.
Then according to (A-COMM), if we compose the two, forming $P\comp Q$, then the simultaneous (compositionally) occurrence of an input action $\receives{c}{\tuple{X}}$ and matching output action $\exports{\tuple{B}}\sends{c}{\tuple{V}}$ can be replaced with $\tau$.
That is, we can say:
\[
	P\comp Q \evolves{\tau} \new{\tuple{B}}(P'\comp Q'),
\]
Note that the exported names $\exports{\tuple{B}}$ are now scoped to both processes as a result of the original term $Q$ exporting them.  
Just as in (A-COMP), we need to make sure that none of these exported names are going to capture free terms in $P$.  
Hence, we require that $\exports{\tuple{B}}\cap fn(P) = \emptyset$.

\begin{example}{exsynchronous_actions}
	In \refex{exsynchronous}, we defined a simple process for modeling (recursive) synchronous sends:
\[
	F_1(c) \pdef \rec{z} (\new{ack}(\send{c}{ack} \comp \receive{ack}{}(R \comp z)))\\
\]
We then went on to show how this process might work as a component in a example system.  
But suppose we wanted to characterize this process' behavior in general.  
We could use reduction semantics to described how it it can evolve internally (in this case there isn't much interesting we can do except unwind the recursion), but we'd also want to include a description of how that process behaves externally.  
If possible, we'd like to do this without having to come up with a system in which to place the process.  
We don't want our characterization of the process to rely on some auxiliary system.  
Without defining a particular system for it to work in, we can use action semantics to provide a characterization of how $F_1(c)$ behaves externally.  
Consider the following inferences:
\begin{center}\begin{tabular}{lllr}
	$F_1(c)$ & $\evolves{\tau}$ & $\new{ack}(\send{c}{ack} \comp \receive{ack}{}(R \comp F_1\langle c\rangle))$ & \tiny{(A-REP)}\\
	& $\evolves{\exports{ack}\sends{c}{ack}}$ & $\pstop \comp \receive{ack}{}(R \comp F_1\langle c\rangle)$ & \tiny{(A-OPEN, A-OUT)}\\
	& $\evolves{\exports{\receives{ack}{}}}$ & $\pstop \comp (R \comp F_1\langle c\rangle)$& \tiny{(A-IN)}\\
\end{tabular}\end{center}
Using the \hyperref[Structural Equivalence]{structural equivalence} rule (S-COMP-ID),  
we know the final step of this sequence of action results in a process equivalent to:
\[
	R \comp F_1(c)
\]
Above, we have shown presence of the important behaviors we expect in $F_1(c)$.  
That is, we have shown that $F_(c)$ can:
\begin{itemize}
\item Recursively spawn a process that can...
\item Send $ack$ over $c$, extruding its scope and resulting in a residual process that can...
\item Receive the acknowledgement handshake on $ack$, resulting in a residual that can... 
\item Run $R$ and wait for the next recursive iteration to occur (internally).
\end{itemize}
Thus, we have completely characterized $F_1(c)$'s capabilities to act as a recursive synchronous output process in a larger system --- and we have done so without having to say anything about what that larger system actually looks like. 
\end{example}

\section{Extended Example: Memory Cells}\label{secmemcells}
	We said in Chapter \ref{Introduction} that distributed systems usually involve information that is shared between processes executing independently on multiple machines.  
In the \picalc, the principle means of sharing information is via message passing.  
Suppose that we wanted instead to model a memory cell that stores information in a less fleeting way.  
Our cell might have channels for getting and setting its value.
A process could use the $get$ channel to request that the value be sent back over a supplied channel.
Passing a new value on the $set$ channel would result in the cell changing it's value to the value supplied.
The main point of our memory cell is that multiple processes could use the cell's getter channel without the value disappearing.
It turns out that we can create this cell just using message passing.  
This section will explore the creation and use of a memory cell, which serves as a good review and usage example of the concepts introduced in this chapter.

	The problem that we have to work around is that receiving a identifier from a channel removes that value from the channel.  
It cannot be retrieved again by some other process.  
Thus, we need a way to push it back in for the next time.  
Consider the following system:
	\begin{equation}\begin{split}
		Cell(get,set) \pdef \new{c} & (\send{c}{init} \\
		& \comp\rec{g}(\receive{get}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y}\comp g))\\
		&\comp\rec{s}(\receive{set}{x,b}\receive{c}{y}(\send{x}{b}\comp\send{c}{b}\comp s)))
	\end{split}\end{equation}
	In $Cell$, we first create a new channel $c$ that will be used to `store' the value.  
We then initialize $c$ with the value $init$.  
The following line has a recursive listener process that, when given a channel $x$ via $get$, gets the value from $c$ and sends it back via $x$.  
In parallel, it sends the value back into $c$ so it can be retrieved again.  
The next line is similar except that two values are supplied via $set$ -- a new value $b$ and a channel $x$.  
The old value is pulled from $c$ and simply discarded (i.e. not used).  
The new value $b$ is pushed to $c$ this time.  
It is also sent via $x$ as an acknowledgment that the cell's new value has been set.
	 
Now let use look at how this memory cell might be used.
In the following system we assume that we have access to the integers and standard arithmetic operations\footnote{See \cite[miln99] for an example of how the integers and arithmetic operations can be build from \picalc\ primitives.}.  
The memory cells are initialized with the integer 0.  
We also give an exposed `output' channel $o$.
	\begin{equation}\begin{split}
		MemoryClient(get_1,set_1,o)\pdef & (\new{a}(\send{get_1}{a}\\
		& \comp \new{a_2}(\receive{a}{y} \send{set_1}{y+1,a_2} \comp \receive{a_2}{z}\send{o}{z}))
	\end{split}\end{equation}
	The system gets the current value from the channel $get_1$ and then uses that value to send an incremented value to $set_1$, receiving acknowledgement on channel $a_2$.
The value received on $a_2$ is sent to the output channel.  
Notice that we created new channels for acknowledgement but left the cell's channels free and exposed.  
Thus, the two components might be put together in the following system (which leaves the output channel free):
\[
	\new{get_1,set_1}(Cell\langle get_1,set_1\rangle \comp MemoryClient\langle get_1,set_1,o\rangle)
\]	
	To see why this system produces the behavior we expect, we substitute the definitions for $Cell$ and $MemoryClient$ into the system and observe scope restrictors for $a$ and $a_2$ can be moved out using (S-REST-COMP):
	\begin{equation}\begin{split}
		\new{get_1, set_1,a,a_2}&(\new{c} (\send{c}{init} \\
			&\comp\rec{g}(\receive{get_1}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y}\comp g))\\
			&\comp\rec{s}(\receive{set_1}{x,b}\receive{c}{y}(\send{x}{b}\comp\send{c}{b}\comp s)))\\
			&\comp \send{get_1}{a}\\
			&\comp \receive{a}{y} \send{set_1}{y+1,a_2} \comp \receive{a_2}{z}\send{o}{z})
	\end{split}\end{equation}
We need to first apply (R-REP), since we'd like to work with the $get_1$ receiver which is inside the $rec$ operator.
\begin{equation}\begin{split}
	\new{get_1, set_1,a,a_2}&(\new{c} (\send{c}{init} \\
		&\comp \receive{get_1}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y} \\
		&\comp\rec{g}(\receive{get_1}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y}\comp g))\\
		&\comp\rec{s}(\receive{set_1}{x,b}\receive{c}{y}(\send{x}{b}\comp\send{c}{b}\comp s)))\\
		&\comp \send{get_1}{a}\\
		&\comp \receive{a}{y} \send{set_1}{y+1,a_2} \comp \receive{a_2}{z}\send{o}{z})
\end{split}\end{equation}
Now we can apply (R-COMM) to the memory cell's getter, performing the substitution $\subst{a}{x}$ to the term $\receive{c}{y}(\send{x}{y}\comp \send{c}{y}$...
\begin{equation}\begin{split}
	\new{get_1, set_1,a,a_2}&(\new{c} (\send{c}{init} \\
		&\comp \receive{c}{y}(\send{a}{y}\comp \send{c}{y} \\
		&\comp\rec{g}(\receive{get_1}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y}\comp g))\\
		&\comp\rec{s}(\receive{set_1}{x,b}\receive{c}{y}(\send{x}{b}\comp\send{c}{b}\comp s)))\\
		&\comp \receive{a}{y} \send{set_1}{y+1,a_2} \comp \receive{a_2}{z}\send{o}{z})
\end{split}\end{equation}
...and apply it once again to the memory's `internal' channel $c$, stripping out the initializer and substituting in the value $init$:
\begin{equation}\begin{split}
	\new{get_1, set_1,a,a_2}&(\new{c} (\\
		&\comp \send{a}{init}\comp \send{c}{init} \\
		&\comp\rec{g}(\receive{get_1}{x}\receive{c}{y}(\send{x}{y}\comp \send{c}{y}\comp g)\\
		&\comp\rec{s}(\receive{set_1}{x,b}\receive{c}{y}(\send{x}{b}\comp\send{c}{b}\comp s)))\\
		&\comp \receive{a}{y} \send{set_1}{y+1,a_2} \comp \receive{a_2}{z}\send{o}{z})
\end{split}\end{equation}
Which, with one more (R-COMM), finally sends back the $init$ value to the $MemoryClient$ on $a$.  
It should now be quite painfully obvious why action semantics would be a better way to analyze the behavior of our memory cell.  

It is nice to have a consistent memory cell that many processes can access at once.
However, there is a classic issue that often arises in the use of shared memory like ours.
Consider the following modification to our system:
\begin{equation}\begin{split}
	\new{get_1,set_1}&(Cell\langle get_1, set_1\rangle\\
	 &\comp  MemoryClient_1\langle get_1,set_1,o\rangle \\
	 &\comp  MemoryClient_2\langle get_1,set_1,o\rangle)\\
\end{split}\end{equation}
If we were run these as such, we may find that the output channel was producing some unexpected results.  
This is because our system contains a \defmargin{race condition}, which means that the output of a system is dependent on the timing of computations in the system.
For example, consider what happens if $MemoryClient_1$ gets the value 0 of the cell first, but before it can set it $MemoryClient_2$ steps in, receives the 0 again and then sets the cell to 1.  
In that case, $MemoryClient_1$ will have a value for the cell (0) that is no longer current.  
It will then set the value of the cell to 1 again, where we would expect it to set 2 since the two clients each incremented once.

Race conditions often occur in concurrent programs where access to a location in computer memory is shared between multiple threads.  In such systems, as in ours, to order in which threads read and manipulate the shared memory is not predictable or consistent.  Hence, concurrent application developers have long been accustomed to using programmatic devices to avoid race conditions.

The usual solution to this type of problem is by implementing a \defmargin{lock}.  
A lock ensures that only one client at a time is doing critical operations like incrementing a value.  
The client asks for the lock, and if it aquires it it proceeds with its critical operations before giving up the lock.  
If the lock is not available, the client has to wait until another client \emph{releases} it.
A lock provides mutually exclusive access to a memory cell.
Normally, a client will lock the cell in order to read and/or modify it, releasing the lock when finished.
Asynchronous channels map naturally to this type of behavior, as we will see in our $MemoryClient$, which we can modify to use a lock.  

Given a channel $l$, we use the short hand $l?lock.P$ to mean:
\[
	\rec{q}(\receive{l}{x} \pif{x=\ptrue}\pthen (P\comp \send{l}{\pfalse})\pelse(q \comp \send{l}{\pfalse}))
\]
Above we check the lock channel $l$ and execute $P$ if it is currently set to $\ptrue$ (meaning the lock is still available). 
Otherwise we recursively try to get the lock again.
Notice that whether the lock is already set to \pfalse or we are able to acquire it, we need to send\pfalse to $l$ so that another process can't acquire the lock.

Let's use action semantics to make sure locking behaves as expected.  
We first note using (A-REP) that the above can internally evolve over $\tau$ to
\begin{equation}\begin{split}
	\evolves{\tau} & \receive{l}{x} \pif{x=\ptrue}\pthen(P\comp \send{l}{\pfalse})\pelse\\
	&(l?lock.P \comp \send{l}{\pfalse})
\end{split}\end{equation}
If $\receive{l}{x}$ receives a \ptrue, then
\begin{equation}\begin{split}
	\evolves{\receives{c}{\ptrue}} & \pif{\ptrue=\ptrue}\pthen(P\comp \send{l}{\pfalse})\pelse\\
	&(l?lock.P \comp \send{l}{\pfalse})
\end{split}\end{equation}
We can now apply (A-EQ), yielding:
\begin{equation}\begin{split}
	\evolves{\tau} & P\comp \send{l}{\pfalse}\\
\end{split}\end{equation}
As expected.  Otherwise, if $\receive{l}{x}$ receives a \pfalse, then $l?lock.P$
\begin{equation}\begin{split}
	\evolves{\receives{c}{\pfalse}} & \pif{\pfalse=\ptrue}\pthen(P\comp \send{l}{\pfalse})\pelse\\
	&(l?lock.P \comp \send{l}{\pfalse})
\end{split}\end{equation}
This time using (A-NEQ),
\begin{equation}\begin{split}
	\evolves{\tau} &l?lock.P \comp \send{l}{\pfalse}
\end{split}\end{equation}
Which again is what we would expect.  
Thus, we have verified that the lock works as expected.\todo{line up all the above equations by putting them in one array and using breaks}

Now, unlocking is done via the shorthand $l!unlock$, meaning
\[
	\receive{l}{x} \send{l}{\ptrue}
\]
This term simply discards the current $l$ value and sets it to $\ptrue$.  

Our $MemoryClient$ thus becomes:
\begin{equation}\begin{split}
	LMemoryClient(get_1,set_1,o,l)\pdef & (\new{a}(l?lock.(\send{get_1}{a}\\
	&\comp \new{a_2}(\receive{a}{y} \send{set_1}{y+1,a_2}\\
	&\comp \receive{a_2}{z}(l!unlock\comp \send{o}{z}))))
\end{split}\end{equation}
Note that the lock $l$ is exposed.  
It needs to be initialized to $\ptrue$ by the system that defines it so that the first process trying to get the lock can get it.   
We will return to the subject of locks in Chapter \ref{sync_and_dist_sys}, where they play a surprisingly similar role in the implementation of a synchronous \picalc.