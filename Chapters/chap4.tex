\chapter{Synchronicity and Distributed Systems}\label{sync_and_dist_sys}
The second question we might ask is about the implementation of a synchronous \picalc.  
On distributed systems, which seem like the natural setting for such an implementation, we have only asynchronous available to us.  
Hence, depending on the answer to the first question, we may have to 

However, whether the asynchronous calculus actually has the expressive power of its synchronous forebear is a matter of more complexity.  
In fact, we will see by straightforward counterexample (and by a rather less straightforward argument due to Palamidessi \cite{palam03}) that two are not truly equal.
\todo{make a note about why the original example only covered input guarded choice}
The implementation of synchronous calculi on distributed systems is a thorny issue.  
On the one hand, it is a useful construct in that it allows us to model many problems more naturally and easily.  
On the other, all communication in a distributed system is in fact asynchronous in nature, and so synchronous communication must be layered on top at some level of the implementation.  
It is notoriously difficult construct to implement synchronous communication efficiently without violating the requirements of a truly distributed system where there is shared memory or central control process.  
The issue becomes more difficult still with the Palamidessi's related requirement of symmetry, which means that a process's behavior does not depend on its location in the channel topology. 

The creators of Pict, the Join-calculus, and other implementations based on the \picalc\ all decided to have their primitives support only asynchronous communication, while synchronous communication is made available overtop of this via a library or higher-level language.  
This these greatly simplifies implementation, resulting in a cleaner, more efficient core language.  
The summation operator in particular is difficult and expensive to fully simulate.  
In the implementation of Pict, for example, David Turner notes \cite{turner96} that ``the additional costs imposed by summation are unacceptable.''.  
Turner goes on to say that essential uses of summation are infrequent in practice.

How can we reconcile this with Palamidessi's result, which indicates that there are important problems that cannot be solved without the full generality of the synchronous calculus?  Is such a calculus even implementable at any cost on distributed systems?  We will see that relaxing any of Palamidessi's assumptions enables a full encoding.  
Some of such encodings derive from the classic distributed solutions to the problem of synchronous communication but strain important assumptions about symmetry in ways that we may not be comfortable allowing.  
Palamidessi herself gives as important probabilistic encoding \cite{palam01} which does not break symmetry.

\section{Symmetry in Practice}

Speaking in an interview on developing the \picalc, Robin Milner notes \cite{miln03}:
\begin{quote}
That was to me the challenge: picking communication primitives which could be understood at a reasonably high level as well as in the way these systems are implemented at a very low level...There's a subtle change from the Turing-like question of what are the fundamental, smallest sets of primitives that you can find to understand computation...as we move towards mobility... we are in a terrific tension between (a) finding a small set of primitives and (b) modeling the real world accurately.
\end{quote}
This tension is quite evident in the efforts of process algebraists to find the `right' calculus for modeling distributed systems.  
While the synchronous \picalc\ more elegantly and (given certain assumptions) completely expresses distributed systems, actual implementation must commit to asynchronous communication as their primitives.  
Which we choose as a model depends in part on our goals.  
In any case, it is evident that by limiting ourselves to smaller calculi, many useful new concepts and structures arise in order to solve the problems posed by asynchronous communication.  
While these structures might not belong in the `smallest set of primitives', they are useful for bringing the power of the \picalc\ to a model that more closely resembles the implementation of distributed systems.

This section will go on to talk about on Nestmann and other implementation-driven encodings, how much they violate uniformity/reasonableness and whether that has any means for the API as a good model for implementable distributed languages.